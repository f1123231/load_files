当前使用设备：cpu
开始加载数据...
数据加载完成，形状：(1025, 33)
发现25个唯一工况：[(1000, 0), (1000, 20), (1000, 40), (1000, 60), (1500, 0), (1500, 20), (1500, 40), (1500, 60), (1797, 0), (1800, 0), (1800, 20), (1800, 40), (1800, 60), (2000, 0), (2000, 20), (2000, 40), (2000, 60), (2500, 0), (2500, 20), (2500, 40), (2500, 60), (3000, 0), (3000, 20), (3000, 40), (3000, 60)]

===== 开始留一工况交叉验证 =====
数据预处理开始...
只保留需要的列后的data的形状：(1025, 32)
总共发现 25 个独立工况: [(1000, 0), (1000, 20), (1000, 40), (1000, 60), (1500, 0), (1500, 20), (1500, 40), (1500, 60), (1797, 0), (1800, 0), (1800, 20), (1800, 40), (1800, 60), (2000, 0), (2000, 20), (2000, 40), (2000, 60), (2500, 0), (2500, 20), (2500, 40), (2500, 60), (3000, 0), (3000, 20), (3000, 40), (3000, 60)]

--- 外层循环：指定测试工况为 (1000, 0) ---
测试工况 (1000, 0) 的样本数: 41
用于划分训练+验证的剩余工况样本总数: 984
  --- 内层循环：指定验证工况为 (1000, 20) ---
验证工况 (1000, 20) 的样本数: 41
训练集包含的工况数: 23, 样本数: 943
对当前训练集进行数据清洗...
  训练 数据形状(缺失值处理后): (943, 32)
  训练 数据形状(异常值处理后)：(943, 32)
对当前验证集进行数据清洗...
  验证 数据形状(缺失值处理后): (41, 32)
  验证 数据形状(异常值处理后)：(41, 32)
对当前测试集进行数据清洗...
  测试 数据形状(缺失值处理后): (41, 32)
  测试 数据形状(异常值处理后)：(41, 32)

--- 第 1 折 / 25 ---
  测试工况: (1000, 0), 验证工况: (1000, 20)
  训练集大小: 943, 验证集大小: 41, 测试集大小: 41
  数据加载器创建完成。
  模型 FrequencyAwareProbabilisticMultiTaskModel 初始化完成。输入维度: 2, 输出维度: 30
准备优化器和损失函数...
- 自适应损失函数 (FrequencyAwareAdaptiveWeightLoss) 创建成功，低频阈值: 6, 低频增强: 2.0
  - 主损失函数 (GaussianNLLLoss, reduction='none') 创建成功。
  - 参数分组：共享层 10 个参数张量，低频特定层 56 个，高频特定层 152 个，自适应损失 1 个。
  - Adam 优化器创建成功。基础 LR: 0.0005, 低频 LR: 0.001, 高频 LR: 0.0005, 自适应损失 LR: 0.01, Weight Decay: 1e-05
  - ReduceLROnPlateau 学习率调度器创建成功。Factor: 0.5, Patience: 10
优化器和损失函数准备完毕。

  开始训练...
开始训练模型，共300个epochs，早停耐心设置为15...
D:\Anaconda\Lib\site-packages\torch\optim\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch [1/300], Train Loss: 1.8491, Val NLL Loss: 2.4311
  Validation loss 改善，保存当前最佳模型。
Epoch [2/300], Train Loss: 1.6375, Val NLL Loss: 1.9454
  Validation loss 改善，保存当前最佳模型。
Epoch [3/300], Train Loss: 1.4006, Val NLL Loss: 1.6541
  Validation loss 改善，保存当前最佳模型。
Epoch [4/300], Train Loss: 1.2172, Val NLL Loss: 1.5452
  Validation loss 改善，保存当前最佳模型。
Epoch [5/300], Train Loss: 1.0463, Val NLL Loss: 1.8573
  Validation loss 未改善 (1/15).
Epoch [6/300], Train Loss: 0.9430, Val NLL Loss: 1.7069
  Validation loss 未改善 (2/15).
Epoch [7/300], Train Loss: 0.8493, Val NLL Loss: 2.0663
  Validation loss 未改善 (3/15).
Epoch [8/300], Train Loss: 0.7999, Val NLL Loss: 2.4016
  Validation loss 未改善 (4/15).
Epoch [9/300], Train Loss: 0.7430, Val NLL Loss: 2.9292
  Validation loss 未改善 (5/15).
Epoch [10/300], Train Loss: 0.7142, Val NLL Loss: 3.0959
  Validation loss 未改善 (6/15).
Epoch [11/300], Train Loss: 0.6720, Val NLL Loss: 2.7424
  Validation loss 未改善 (7/15).
Epoch [12/300], Train Loss: 0.6480, Val NLL Loss: 2.6213
  Validation loss 未改善 (8/15).
Epoch [13/300], Train Loss: 0.6501, Val NLL Loss: 2.5742
  Validation loss 未改善 (9/15).
Epoch [14/300], Train Loss: 0.6039, Val NLL Loss: 2.8757
  Validation loss 未改善 (10/15).
Epoch [15/300], Train Loss: 0.5834, Val NLL Loss: 3.3276
  Validation loss 未改善 (11/15).
Epoch [16/300], Train Loss: 0.5536, Val NLL Loss: 3.5389
  Validation loss 未改善 (12/15).
Epoch [17/300], Train Loss: 0.5495, Val NLL Loss: 3.5029
  Validation loss 未改善 (13/15).
Epoch [18/300], Train Loss: 0.5387, Val NLL Loss: 3.8984
  Validation loss 未改善 (14/15).
Epoch [19/300], Train Loss: 0.5363, Val NLL Loss: 3.3898
  Validation loss 未改善 (15/15).

早停触发：验证损失连续 15 epochs 未改善。停止训练于 epoch 19。

训练结束。加载验证损失最小 (NLL Loss: 1.5452) 时的模型权重。
  已加载最佳模型权重 (验证 NLL Loss: 1.5452)。
  开始评估...
开始在测试集上评估模型...

测试集评估完成:
  平均 NLL Loss (标准化尺度): 3.8532
  平均 MSE Loss (原始尺度): 31.9287
  平均 MAE Loss (原始尺度): 4.9378
  测试工况 (1000, 0) 评估指标已记录。
  测试工况 (1000, 0) 误差分析结果已记录。
图表已保存至: analysis_and_plots\prediction_uncertainty_cond_1000_0.png
  --- 内层循环：指定验证工况为 (1000, 40) ---
验证工况 (1000, 40) 的样本数: 41
训练集包含的工况数: 23, 样本数: 943
对当前训练集进行数据清洗...
  训练 数据形状(缺失值处理后): (943, 32)
  训练 数据形状(异常值处理后)：(943, 32)
对当前验证集进行数据清洗...
  验证 数据形状(缺失值处理后): (41, 32)
  验证 数据形状(异常值处理后)：(41, 32)
对当前测试集进行数据清洗...
  测试 数据形状(缺失值处理后): (41, 32)
  测试 数据形状(异常值处理后)：(41, 32)

--- 第 2 折 / 25 ---
  测试工况: (1000, 0), 验证工况: (1000, 40)
  训练集大小: 943, 验证集大小: 41, 测试集大小: 41
  数据加载器创建完成。
D:\Anaconda\Lib\site-packages\torch\optim\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
  模型 FrequencyAwareProbabilisticMultiTaskModel 初始化完成。输入维度: 2, 输出维度: 30
准备优化器和损失函数...
- 自适应损失函数 (FrequencyAwareAdaptiveWeightLoss) 创建成功，低频阈值: 6, 低频增强: 2.0
  - 主损失函数 (GaussianNLLLoss, reduction='none') 创建成功。
  - 参数分组：共享层 10 个参数张量，低频特定层 56 个，高频特定层 152 个，自适应损失 1 个。
  - Adam 优化器创建成功。基础 LR: 0.0005, 低频 LR: 0.001, 高频 LR: 0.0005, 自适应损失 LR: 0.01, Weight Decay: 1e-05
  - ReduceLROnPlateau 学习率调度器创建成功。Factor: 0.5, Patience: 10
优化器和损失函数准备完毕。

  开始训练...
开始训练模型，共300个epochs，早停耐心设置为15...
Epoch [1/300], Train Loss: 1.8975, Val NLL Loss: 1.9681
  Validation loss 改善，保存当前最佳模型。
Epoch [2/300], Train Loss: 1.6240, Val NLL Loss: 1.4981
  Validation loss 改善，保存当前最佳模型。
Epoch [3/300], Train Loss: 1.3987, Val NLL Loss: 1.1213
  Validation loss 改善，保存当前最佳模型。
Epoch [4/300], Train Loss: 1.2201, Val NLL Loss: 0.8427
  Validation loss 改善，保存当前最佳模型。
Epoch [5/300], Train Loss: 1.0662, Val NLL Loss: 0.6856
  Validation loss 改善，保存当前最佳模型。
Epoch [6/300], Train Loss: 0.9651, Val NLL Loss: 0.4703
  Validation loss 改善，保存当前最佳模型。
Epoch [7/300], Train Loss: 0.8748, Val NLL Loss: 0.3497
  Validation loss 改善，保存当前最佳模型。
Epoch [8/300], Train Loss: 0.7759, Val NLL Loss: 0.3709
  Validation loss 未改善 (1/15).
Epoch [9/300], Train Loss: 0.7284, Val NLL Loss: 0.1906
  Validation loss 改善，保存当前最佳模型。
Epoch [10/300], Train Loss: 0.6993, Val NLL Loss: 0.3328
  Validation loss 未改善 (1/15).
Epoch [11/300], Train Loss: 0.6776, Val NLL Loss: 0.1657
  Validation loss 改善，保存当前最佳模型。
Epoch [12/300], Train Loss: 0.6332, Val NLL Loss: 0.2397
  Validation loss 未改善 (1/15).
Epoch [13/300], Train Loss: 0.6068, Val NLL Loss: 0.2797
  Validation loss 未改善 (2/15).
Epoch [14/300], Train Loss: 0.5906, Val NLL Loss: 0.2504
  Validation loss 未改善 (3/15).
Epoch [15/300], Train Loss: 0.5817, Val NLL Loss: 0.2941
  Validation loss 未改善 (4/15).
Epoch [16/300], Train Loss: 0.5566, Val NLL Loss: 0.3934
  Validation loss 未改善 (5/15).
Epoch [17/300], Train Loss: 0.5466, Val NLL Loss: 0.6397
  Validation loss 未改善 (6/15).
Epoch [18/300], Train Loss: 0.5286, Val NLL Loss: 0.4312
  Validation loss 未改善 (7/15).
Epoch [19/300], Train Loss: 0.5182, Val NLL Loss: 0.3772
  Validation loss 未改善 (8/15).
Epoch [20/300], Train Loss: 0.5004, Val NLL Loss: 0.3582
  Validation loss 未改善 (9/15).
Epoch [21/300], Train Loss: 0.4929, Val NLL Loss: 0.2935
  Validation loss 未改善 (10/15).
Epoch [22/300], Train Loss: 0.4947, Val NLL Loss: 0.4212
  Validation loss 未改善 (11/15).
Epoch [23/300], Train Loss: 0.4583, Val NLL Loss: 0.3632
  Validation loss 未改善 (12/15).
Epoch [24/300], Train Loss: 0.4527, Val NLL Loss: 0.3926
  Validation loss 未改善 (13/15).
Epoch [25/300], Train Loss: 0.4528, Val NLL Loss: 0.3907
  Validation loss 未改善 (14/15).
Epoch [26/300], Train Loss: 0.4411, Val NLL Loss: 0.3250
  Validation loss 未改善 (15/15).

早停触发：验证损失连续 15 epochs 未改善。停止训练于 epoch 26。

训练结束。加载验证损失最小 (NLL Loss: 0.1657) 时的模型权重。
  已加载最佳模型权重 (验证 NLL Loss: 0.1657)。
  开始评估...
开始在测试集上评估模型...

测试集评估完成:
  平均 NLL Loss (标准化尺度): 2.8816
  平均 MSE Loss (原始尺度): 15.8161
  平均 MAE Loss (原始尺度): 3.4460
  测试工况 (1000, 0) 评估指标已记录。
  测试工况 (1000, 0) 误差分析结果已记录。
图表已保存至: analysis_and_plots\prediction_uncertainty_cond_1000_0.png
  --- 内层循环：指定验证工况为 (1000, 60) ---
验证工况 (1000, 60) 的样本数: 41
训练集包含的工况数: 23, 样本数: 943
对当前训练集进行数据清洗...
  训练 数据形状(缺失值处理后): (943, 32)
  训练 数据形状(异常值处理后)：(943, 32)
对当前验证集进行数据清洗...
  验证 数据形状(缺失值处理后): (41, 32)
  验证 数据形状(异常值处理后)：(41, 32)
对当前测试集进行数据清洗...
  测试 数据形状(缺失值处理后): (41, 32)
  测试 数据形状(异常值处理后)：(41, 32)